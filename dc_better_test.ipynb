{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-28T10:41:23.338871900Z",
     "start_time": "2024-05-28T10:40:42.316252100Z"
    }
   },
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier, VotingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Load the data\n",
    "# Load the data with ';' delimiter\n",
    "measures = pd.read_csv('measures.csv', delimiter=';')\n",
    "to_predict = pd.read_csv('to_predict.csv', delimiter=';')\n",
    "\n",
    "# Convert comma decimal separator to dot and convert columns to appropriate types\n",
    "measures = measures.map(lambda x: x.replace(',', '.') if isinstance(x, str) else x)\n",
    "measures = measures.astype({col: float for col in measures.columns if col not in ['subject', 'activity']})\n",
    "measures['subject'] = measures['subject'].astype(float)\n",
    "\n",
    "to_predict = to_predict.map(lambda x: x.replace(',', '.') if isinstance(x, str) else x)\n",
    "to_predict = to_predict.astype({col: float for col in measures.columns if col not in ['subject', 'activity']})\n",
    "\n",
    "# Define the subjects for training and test sets\n",
    "training_subjects =      [1, 3, 5, 6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26]\n",
    "test_subjects = [27, 28, 29, 30]\n",
    "\n",
    "# Split the measures dataset into training and test sets\n",
    "training_set = measures[measures['subject'].isin(training_subjects)]\n",
    "test_set = measures[measures['subject'].isin(test_subjects)]\n",
    "\n",
    "# Ensure there's no overlap\n",
    "assert not training_set['subject'].isin(test_subjects).any(), \"Training and test sets overlap!\"\n",
    "\n",
    "# Define features and labels\n",
    "X_train = training_set.drop(columns=['subject', 'activity'])\n",
    "y_train = training_set['activity']\n",
    "\n",
    "X_test = test_set.drop(columns=['subject', 'activity'])\n",
    "y_test = test_set['activity']\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tGravityAcc-mean()-X      0.034425\n",
      "angle(X,gravityMean)      0.033263\n",
      "tGravityAcc-mean()-Y      0.030730\n",
      "tGravityAcc-max()-X       0.027335\n",
      "tGravityAcc-min()-Y       0.027280\n",
      "tGravityAcc-min()-X       0.022995\n",
      "angle(Y,gravityMean)      0.022869\n",
      "tGravityAcc-energy()-X    0.021537\n",
      "tGravityAcc-max()-Y       0.021520\n",
      "tGravityAcc-energy()-Y    0.017830\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Assuming X_train and y_train are already defined as shown in previous steps\n",
    "\n",
    "# Train a RandomForestClassifier to evaluate feature importance\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Get feature importances\n",
    "feature_importances = pd.Series(rf_model.feature_importances_, index=X_train.columns)\n",
    "\n",
    "# Display the top 10 most important features\n",
    "top_features = feature_importances.nlargest(10)\n",
    "print(top_features)\n",
    "\n",
    "\n",
    "# Create new datasets with top features\n",
    "X_train_top = X_train[top_features.index]\n",
    "X_test_top = X_test[top_features.index]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-28T10:57:12.469840100Z",
     "start_time": "2024-05-28T10:55:38.642092400Z"
    }
   },
   "id": "e74dfae9ff717dae",
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "source": [
    "1. Optimal Feature Selection:\n",
    "Let's try selecting a different number of top features to see if we can find a better subset. We can use methods like Recursive Feature Elimination (RFE) with cross-validation to determine the optimal number of features.\n",
    "\n",
    "2. Recursive Feature Elimination with Cross-Validation (RFECV):\n",
    "This method helps find the best number of features by recursively removing the least important features and evaluating the model's performance.\n",
    "\n",
    "Here is the code to perform RFECV:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "56e5c30afd10054d"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# Initialize the model\n",
    "rf_model = RandomForestClassifier(n_estimators=5, random_state=42)\n",
    "log_reg = LogisticRegression(max_iter=1000, C=38, dual=False)\n",
    "\n",
    "# Initialize RFECV\n",
    "rfecv = RFECV(estimator=log_reg, step=1, cv=StratifiedKFold(5), scoring='accuracy')\n",
    "\n",
    "# Fit RFECV\n",
    "rfecv.fit(X_train, y_train)\n",
    "\n",
    "# Get the optimal number of features\n",
    "optimal_num_features = rfecv.n_features_\n",
    "print(\"Optimal number of features:\", optimal_num_features)\n",
    "\n",
    "# Get the support and ranking of features\n",
    "selected_features = X_train.columns[rfecv.support_]\n",
    "print(\"Selected features:\", selected_features)\n",
    "\n",
    "# Create new datasets with selected features\n",
    "X_train_optimal = X_train[selected_features]\n",
    "X_test_optimal = X_test[selected_features]\n",
    "\n",
    "# Train model using optimal features\n",
    "rf_model_optimal = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "log_reg = LogisticRegression(max_iter=10000, C=38, dual=False)\n",
    "rf_model_optimal.fit(X_train_optimal, y_train)\n",
    "accuracy_optimal = rf_model_optimal.score(X_test_optimal, y_test)\n",
    "print(\"Test Set Accuracy with Optimal Features:\", accuracy_optimal)\n"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2024-05-29T11:50:49.113218800Z"
    }
   },
   "id": "606281338bbfdc6f",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> 0.9717171717171718\n",
      "\n",
      "Ensemble Model:\n",
      "Test Set Accuracy: 0.9717171717171718\n"
     ]
    }
   ],
   "source": [
    "# Initialize classifiers with chosen hyperparameters\n",
    "svm = SVC(C=40, gamma=0.055, kernel='rbf', probability=True)\n",
    "knn = KNeighborsClassifier(n_neighbors=7, weights='distance')\n",
    "dt = DecisionTreeClassifier(max_depth=100, min_samples_split=2)\n",
    "rf = RandomForestClassifier(max_depth=100, n_estimators=1000)\n",
    "gb = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, max_depth=3)\n",
    "nb = GaussianNB()\n",
    "ada = AdaBoostClassifier(n_estimators=100, learning_rate=1, algorithm=\"SAMME\")\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(100,), activation='relu', solver='lbfgs', alpha=0.002, learning_rate='adaptive', max_iter=2500)\n",
    "xgb = XGBClassifier(n_estimators=500, learning_rate=0.2, max_depth=5, subsample=0.8, colsample_bytree=0.8, use_label_encoder=False, eval_metric='mlogloss')\n",
    "\n",
    "# Define the ensemble of classifiers\n",
    "ensemble = VotingClassifier(estimators=[\n",
    "    ('log_reg', log_reg),\n",
    "    ('svm', svm),\n",
    "    #('knn', knn),\n",
    "    #('dt', dt),\n",
    "    #('rf', rf),\n",
    "    #('gb', gb),\n",
    "    #('nb', nb),\n",
    "    #('ada', ada),\n",
    "    #('mlp', mlp),\n",
    "    #('xgb', xgb)\n",
    "], voting='soft')  # Use 'soft' for probability-based voting\n",
    "\n",
    "# Fit the ensemble model\n",
    "ensemble.fit(X_train, y_train)\n",
    "\n",
    "print(\"-->\", ensemble.score(X_test, y_test))\n",
    "\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = ensemble.predict(X_test)\n",
    "\n",
    "# Calculate accuracy and classification error\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "classification_error = 1 - accuracy\n",
    "\n",
    "# Print the results\n",
    "print(\"\\nEnsemble Model:\")\n",
    "print(\"Test Set Accuracy:\", accuracy)\n",
    "# lr svm Test Set Accuracy: 0.9717171717171718"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-29T11:50:29.175779900Z",
     "start_time": "2024-05-29T11:50:03.225395800Z"
    }
   },
   "id": "b08178a70b805a21",
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top features --> 0.9454545454545454\n"
     ]
    }
   ],
   "source": [
    "ensemble = VotingClassifier(estimators=[\n",
    "    ('log_reg', log_reg),\n",
    "    ('svm', svm)\n",
    "], voting='soft')  # Use 'soft' for probability-based voting\n",
    "\n",
    "ensemble.fit(X_train_optimal, y_train)\n",
    "print(\"top features -->\", ensemble.score(X_test_optimal, y_test))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-29T11:49:51.488860200Z",
     "start_time": "2024-05-29T11:49:48.979141200Z"
    }
   },
   "id": "9f3de92dab00d6a8",
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "17540ef688a01a3e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

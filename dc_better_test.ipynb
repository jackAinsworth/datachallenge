{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-28T10:41:23.338871900Z",
     "start_time": "2024-05-28T10:40:42.316252100Z"
    }
   },
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier, VotingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Load the data\n",
    "# Load the data with ';' delimiter\n",
    "measures = pd.read_csv('measures.csv', delimiter=';')\n",
    "to_predict = pd.read_csv('to_predict.csv', delimiter=';')\n",
    "\n",
    "# Convert comma decimal separator to dot and convert columns to appropriate types\n",
    "measures = measures.map(lambda x: x.replace(',', '.') if isinstance(x, str) else x)\n",
    "measures = measures.astype({col: float for col in measures.columns if col not in ['subject', 'activity']})\n",
    "measures['subject'] = measures['subject'].astype(float)\n",
    "\n",
    "to_predict = to_predict.map(lambda x: x.replace(',', '.') if isinstance(x, str) else x)\n",
    "to_predict = to_predict.astype({col: float for col in measures.columns if col not in ['subject', 'activity']})\n",
    "\n",
    "# Define the subjects for training and test sets\n",
    "training_subjects =      [1, 3, 5, 6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26]\n",
    "test_subjects = [27, 28, 29, 30]\n",
    "\n",
    "# Split the measures dataset into training and test sets\n",
    "training_set = measures[measures['subject'].isin(training_subjects)]\n",
    "test_set = measures[measures['subject'].isin(test_subjects)]\n",
    "\n",
    "# Ensure there's no overlap\n",
    "assert not training_set['subject'].isin(test_subjects).any(), \"Training and test sets overlap!\"\n",
    "\n",
    "# Define features and labels\n",
    "X_train = training_set.drop(columns=['subject', 'activity'])\n",
    "y_train = training_set['activity']\n",
    "\n",
    "X_test = test_set.drop(columns=['subject', 'activity'])\n",
    "y_test = test_set['activity']\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Skaling the data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Scaling the data\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-28T10:57:12.469840100Z",
     "start_time": "2024-05-28T10:55:38.642092400Z"
    }
   },
   "id": "e74dfae9ff717dae",
   "execution_count": 51
  },
  {
   "cell_type": "markdown",
   "source": [
    "1. Optimal Feature Selection:\n",
    "Let's try selecting a different number of top features to see if we can find a better subset. We can use methods like Recursive Feature Elimination (RFE) with cross-validation to determine the optimal number of features.\n",
    "\n",
    "2. Recursive Feature Elimination with Cross-Validation (RFECV):\n",
    "This method helps find the best number of features by recursively removing the least important features and evaluating the model's performance.\n",
    "\n",
    "This is for LogReg"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "56e5c30afd10054d"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n",
      "eval\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# Initialize the model\n",
    "#rf_model = RandomForestClassifier(n_estimators=5, random_state=42)\n",
    "log_reg = LogisticRegression(max_iter=1000, C=38, dual=False)\n",
    "#log_reg = DecisionTreeClassifier(max_depth=1000, min_samples_split=2)\n",
    "\n",
    "\n",
    "print(\"start\")\n",
    "# Initialize RFECV\n",
    "rfecv = RFECV(estimator=log_reg, step=1, cv=StratifiedKFold(5), scoring='accuracy')\n",
    "print(\"eval\")\n",
    "\n",
    "# Fit RFECV\n",
    "rfecv.fit(X_train, y_train)\n",
    "print(\"fitted\")\n",
    "\n",
    "# Get the optimal number of features\n",
    "optimal_num_features = rfecv.n_features_\n",
    "print(\"Optimal number of features:\", optimal_num_features)\n",
    "\n",
    "# Get the support and ranking of features\n",
    "selected_features = X_train.columns[rfecv.support_]\n",
    "print(\"Selected features:\", selected_features)\n",
    "\n",
    "# Create new datasets with selected features\n",
    "X_train_optimal_log_reg = X_train[selected_features]\n",
    "X_test_optimal_log_reg = X_test[selected_features]\n",
    "\n",
    "print(\"modelling\")\n",
    "\n",
    "# Train model using optimal features\n",
    "#rf_model_optimal = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model_optimal = LogisticRegression(max_iter=10000, C=38, dual=False)\n",
    "rf_model_optimal.fit(X_train_optimal_log_reg, y_train)\n",
    "accuracy_optimal = rf_model_optimal.score(X_test_optimal_log_reg, y_test)\n",
    "print(\"Test Set Accuracy with Optimal Features:\", accuracy_optimal)\n",
    "\n",
    "# Optimal number of features: 138\n",
    "# Test Set Accuracy with Optimal Features: 0.9683501683501684\n",
    "# with LogisticRegression(max_iter=10000, C=38, dual=False)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2024-05-29T11:50:49.113218800Z"
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "id": "606281338bbfdc6f",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "This is for SVM"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [],
   "source": [
    "# Initialize classifiers with chosen hyperparameters\n",
    "svm = SVC(C=40, gamma=0.055, kernel='rbf', probability=True)\n",
    "knn = KNeighborsClassifier(n_neighbors=7, weights='distance')\n",
    "dt = DecisionTreeClassifier(max_depth=1000, min_samples_split=2)\n",
    "rf = RandomForestClassifier(max_depth=100, n_estimators=1000)\n",
    "gb = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, max_depth=3)\n",
    "nb = GaussianNB()\n",
    "ada = AdaBoostClassifier(n_estimators=100, learning_rate=1, algorithm=\"SAMME\")\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(100,), activation='relu', solver='lbfgs', alpha=0.002, learning_rate='adaptive', max_iter=2500)\n",
    "xgb = XGBClassifier(n_estimators=500, learning_rate=0.2, max_depth=5, subsample=0.8, colsample_bytree=0.8, use_label_encoder=False, eval_metric='mlogloss')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> 0.9703703703703703\n",
      "\n",
      "Ensemble Model:\n",
      "Test Set Accuracy: 0.9703703703703703\n"
     ]
    }
   ],
   "source": [
    "# Define the ensemble of classifiers\n",
    "ensemble = VotingClassifier(estimators=[\n",
    "    #('log_reg', log_reg),\n",
    "    ('svm', svm),\n",
    "    #('knn', knn),\n",
    "    #('dt', dt),\n",
    "    #('rf', rf),\n",
    "    #('gb', gb),\n",
    "    #('nb', nb),\n",
    "    #('ada', ada),\n",
    "    #('mlp', mlp),\n",
    "    #('xgb', xgb)\n",
    "], voting='soft')  # Use 'soft' for probability-based voting\n",
    "\n",
    "# Fit the ensemble model\n",
    "ensemble.fit(X_train, y_train)\n",
    "\n",
    "print(\"-->\", ensemble.score(X_test, y_test))\n",
    "\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = ensemble.predict(X_test)\n",
    "\n",
    "# Calculate accuracy and classification error\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "classification_error = 1 - accuracy\n",
    "\n",
    "# Print the results\n",
    "print(\"\\nEnsemble Model:\")\n",
    "print(\"Test Set Accuracy:\", accuracy)\n",
    "# lr svm Test Set Accuracy: 0.9717171717171718\n",
    "#nur svm --> 0.9676767676767677\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-29T11:50:29.175779900Z",
     "start_time": "2024-05-29T11:50:03.225395800Z"
    }
   },
   "id": "b08178a70b805a21",
   "execution_count": 48
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top features --> 0.9757575757575757\n"
     ]
    }
   ],
   "source": [
    "ensemble = VotingClassifier(estimators=[\n",
    "    #('log_reg', log_reg),\n",
    "    ('svm', svm),\n",
    "    #('xgb', xgb),\n",
    "    #('mlp', mlp),\n",
    "], voting='soft')  # Use 'soft' for probability-based voting\n",
    "\n",
    "ensemble.fit(X_train_optimal_log_reg, y_train)\n",
    "print(\"top features -->\", ensemble.score(X_test_optimal_log_reg, y_test))\n",
    "\n",
    "# top features --> 0.9730639730639731 mit verbesserung der logReg features\n",
    "# new highest solo SVM top features --> 0.9757575757575757"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-29T11:49:51.488860200Z",
     "start_time": "2024-05-29T11:49:48.979141200Z"
    }
   },
   "id": "9f3de92dab00d6a8",
   "execution_count": 49
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "# Initialize classifiers\n",
    "log_reg = LogisticRegression(max_iter=10000, C=38, dual=False)\n",
    "svm = SVC(C=40, gamma=0.055, kernel='rbf', probability=True)\n",
    "\n",
    "# Define different training sets for each classifier\n",
    "X_train_log_reg = X_train_optimal_log_reg  # Replace with your specific dataset for Logistic Regression\n",
    "X_train_svm = X_train_optimal_svm          # Replace with your specific dataset for SVM\n",
    "y_train_log_reg = y_train                  # Assuming the target variable is the same\n",
    "\n",
    "# Train each classifier on its respective dataset\n",
    "log_reg.fit(X_train_log_reg, y_train_log_reg)\n",
    "svm.fit(X_train_svm, y_train_log_reg)\n",
    "\n",
    "# Make predictions on the test set\n",
    "log_reg_pred_proba = log_reg.predict_proba(X_test_optimal_log_reg)  # Probability predictions for logistic regression\n",
    "svm_pred_proba = svm.predict_proba(X_test_optimal_svm)          # Probability predictions for SVM\n",
    "\n",
    "# Combine predictions using average probabilities (soft voting)\n",
    "combined_pred_proba = (log_reg_pred_proba + svm_pred_proba) / 2\n",
    "combined_pred = np.argmax(combined_pred_proba, axis=1)\n",
    "\n",
    "# Evaluate the combined predictions\n",
    "accuracy = accuracy_score(y_test, combined_pred)\n",
    "print(\"Ensemble accuracy:\", accuracy)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   },
   "id": "17540ef688a01a3e"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

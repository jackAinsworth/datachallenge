{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-23T14:39:49.441878500Z",
     "start_time": "2024-05-23T14:39:46.205594900Z"
    }
   },
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier, VotingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Load the data\n",
    "# Load the data with ';' delimiter\n",
    "measures = pd.read_csv('measures.csv', delimiter=';')\n",
    "to_predict = pd.read_csv('to_predict.csv', delimiter=';')\n",
    "\n",
    "# Convert comma decimal separator to dot and convert columns to appropriate types\n",
    "measures = measures.map(lambda x: x.replace(',', '.') if isinstance(x, str) else x)\n",
    "measures = measures.astype({col: float for col in measures.columns if col not in ['subject', 'activity']})\n",
    "measures['subject'] = measures['subject'].astype(float)\n",
    "\n",
    "to_predict = to_predict.map(lambda x: x.replace(',', '.') if isinstance(x, str) else x)\n",
    "to_predict = to_predict.astype({col: float for col in measures.columns if col not in ['subject', 'activity']})\n",
    "\n",
    "\n",
    "# Select only the columns that include \"entropy\" and the \"subject\" and \"activity\" columns\n",
    "#columns_to_use = [col for col in measures.columns if 'entropy' in col] + ['subject', 'activity']\n",
    "#measures_filtered = measures[columns_to_use]\n",
    "#to_predict_filtered = to_predict[[col for col in to_predict.columns if 'entropy' in col] + ['subject']]\n",
    "\n",
    "# Define the subjects for training and test sets\n",
    "training_subjects = [1, 3, 5, 6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26]\n",
    "test_subjects = [27, 28, 29, 30]\n",
    "\n",
    "# Split the measures dataset into training and test sets\n",
    "training_set = measures[measures['subject'].isin(training_subjects)]\n",
    "test_set = measures[measures['subject'].isin(test_subjects)]\n",
    "\n",
    "# Ensure there's no overlap\n",
    "assert not training_set['subject'].isin(test_subjects).any(), \"Training and test sets overlap!\"\n",
    "\n",
    "# Define features and labels\n",
    "X_train = training_set.drop(columns=['subject', 'activity'])\n",
    "y_train = training_set['activity']\n",
    "\n",
    "X_test = test_set.drop(columns=['subject', 'activity'])\n",
    "y_test = test_set['activity']\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> 0.9656565656565657\n",
      "\n",
      "Ensemble Model:\n",
      "Test Set Accuracy: 0.9656565656565657\n"
     ]
    }
   ],
   "source": [
    "# Initialize classifiers with chosen hyperparameters\n",
    "log_reg = LogisticRegression(max_iter=10000, C=38, dual=False)\n",
    "svm = SVC(C=40, gamma=0.055, kernel='rbf', probability=True)\n",
    "knn = KNeighborsClassifier(n_neighbors=7, weights='distance')\n",
    "dt = DecisionTreeClassifier(max_depth=100, min_samples_split=2)\n",
    "rf = RandomForestClassifier(max_depth=100, n_estimators=1000)\n",
    "gb = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, max_depth=3)\n",
    "nb = GaussianNB()\n",
    "ada = AdaBoostClassifier(n_estimators=100, learning_rate=1, algorithm=\"SAMME\")\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(100,), activation='relu', solver='lbfgs', alpha=0.002, learning_rate='adaptive', max_iter=2500)\n",
    "xgb = XGBClassifier(n_estimators=500, learning_rate=0.2, max_depth=5, subsample=0.8, colsample_bytree=0.8, use_label_encoder=False, eval_metric='mlogloss')\n",
    "\n",
    "# Define the ensemble of classifiers\n",
    "ensemble = VotingClassifier(estimators=[\n",
    "    ('log_reg', log_reg),\n",
    "    ('svm', svm),\n",
    "    #('knn', knn),\n",
    "    #('dt', dt),\n",
    "    #('rf', rf),\n",
    "    #('gb', gb),\n",
    "    #('nb', nb),\n",
    "    #('ada', ada),\n",
    "    #('mlp', mlp),\n",
    "    #('xgb', xgb)\n",
    "], voting='soft')  # Use 'soft' for probability-based voting\n",
    "\n",
    "# Fit the ensemble model\n",
    "ensemble.fit(X_train, y_train)\n",
    "\n",
    "print(\"-->\", ensemble.score(X_test, y_test))\n",
    "\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = ensemble.predict(X_test)\n",
    "\n",
    "# Calculate accuracy and classification error\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "classification_error = 1 - accuracy\n",
    "\n",
    "# Print the results\n",
    "print(\"\\nEnsemble Model:\")\n",
    "print(\"Test Set Accuracy:\", accuracy)\n",
    "\n",
    "#subject 1 bis 16 in training\n",
    "# run one Test Set Accuracy:    0.9602693602693603\n",
    "# nur logReg Test Set Accuracy: 0.9629629629629629\n",
    "# nur svm Test Set Accuracy:    0.9622895622895623\n",
    "# LR und SVM Test Set Accuracy: 0.9663299663299664 !!!\n",
    "# xgb Test Set Accuracy:        0.9488215488215488\n",
    "# xbg lr svm Test Set Accuracy: 0.9643097643097643\n",
    "\n",
    "\n",
    "# xgb optimize Test Set Accuracy:       0.9434343434343434\n",
    "# 0.2 learning rate Test Set Accuracy:  0.9474747474747475\n",
    "# 0.5 Test Set Accuracy:                0.9420875420875421\n",
    "\n",
    "#mlp optimize Test Set Accuracy:              0.938047138047138\n",
    "# solver a -> lb Test Set Accuracy:           0.958922558922559\n",
    "# activision logitic <- al Test Set Accuracy: 0.9501683501683502\n",
    "# alpha von 001 auf .002 Test Set Accuracy:   0.9616161616161616\n",
    "\n",
    "# svm lr mlp noch nicht besser Test Set Accuracy: 0.9602693602693603\n",
    "# opti rf 50 1000 --> 0.9643097643097643\n",
    "# rf 100 1000 --> --> 0.9649831649831649\n",
    " \n",
    "# training mit allen \n",
    "# lr svm Test Set Accuracy: 0.9717171717171718"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-23T15:03:31.015511700Z",
     "start_time": "2024-05-23T14:41:51.229523200Z"
    }
   },
   "id": "57a7e0cba1a77497",
   "execution_count": 69
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\n",
    "# Prepare the to_predict features, ensuring to match the training features\n",
    "#to_predict_features = to_predict_filtered[X_train.columns]\n",
    "\n",
    "# Predict activities in to_predict.csv\n",
    "#predicted_activities = ensemble.predict(to_predict_features)\n",
    "\n",
    "# Add predictions to the to_predict DataFrame\n",
    "#to_predict_filtered['predicted_activity'] = predicted_activities\n",
    "\n",
    "# Display the first few rows with predictions\n",
    "#print(\"\\nPredictions on to_predict.csv:\")\n",
    "#print(to_predict_filtered.head())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-23T14:10:01.422247900Z",
     "start_time": "2024-05-23T14:10:01.417260700Z"
    }
   },
   "id": "8adc255e01e6a98f",
   "execution_count": 47
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "b122ad210c0febf7"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
